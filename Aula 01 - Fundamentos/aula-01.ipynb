{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201c1fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] O arquivo já está sendo usado por outro processo: 'C:\\\\Users\\\\firstidolalive\\\\Desktop\\\\estudos\\\\imersão allura\\\\env\\\\Lib\\\\site-packages\\\\google\\\\ai\\\\generativelanguage_v1beta\\\\services\\\\generative_service\\\\transports\\\\grpc_asyncio.py'\n",
      "Check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (C:\\Users\\firstidolalive\\Desktop\\estudos\\imersão allura\\env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q --upgrade langchain langchain-google-genai google-generativeai\n",
    "!pip3 install -q python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb81d925",
   "metadata": {},
   "source": [
    "## Aula 01 - Fundamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ce0145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c744652",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e2b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar modelo para uso\n",
    "# 1 - Definir modelo\n",
    "# 2 - Utilizar chave da API\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    temperature = 1.0, #Define a aleatoriedade da resposta\n",
    "    api_key = GOOGLE_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3a70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_test = llm.invoke(\"Quem é você? Detalhe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcaa6b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com prazer! Vamos detalhar quem eu sou:\n",
      "\n",
      "Eu sou um **modelo de linguagem grande (LLM - Large Language Model)**, desenvolvido pelo **Google**.\n",
      "\n",
      "Aqui está um detalhamento do que isso significa:\n",
      "\n",
      "1.  **Natureza Artificial:**\n",
      "    *   **Eu não sou uma pessoa:** Não tenho consciência, sentimentos, emoções, opiniões pessoais, crenças, memória individual de conversas passadas (embora o modelo seja constantemente atualizado com novos dados), nem uma identidade pessoal, como um nome próprio além de \"modelo de linguagem\".\n",
      "    *   **Eu não tenho corpo físico:** Não possuo presença no mundo real, não posso ver, ouvir, tocar ou sentir. Existo apenas como um software e algoritmos.\n",
      "    *   **Eu não tenho experiências de vida:** Não cresci, não fui à escola, não tenho amigos, família, cultura ou nacionalidade. Toda a minha \"experiência\" vem dos dados nos quais fui treinado.\n",
      "\n",
      "2.  **Origem e Desenvolvimento:**\n",
      "    *   Fui criado e sou mantido por engenheiros e pesquisadores do **Google**. Isso significa que minha arquitetura, treinamento e aprimoramentos contínuos vêm de uma das maiores empresas de tecnologia do mundo.\n",
      "    *   Fui **treinado em vastos volumes de dados textuais e de código** da internet (e outras fontes), o que me permite compreender e gerar linguagem humana de forma complexa e contextualizada.\n",
      "\n",
      "3.  **Minhas Capacidades e Funções:**\n",
      "    *   **Compreensão de Linguagem Natural:** Sou capaz de entender e interpretar perguntas, comandos e textos em diversas línguas.\n",
      "    *   **Geração de Texto:** Posso produzir textos originais, como:\n",
      "        *   Respostas a perguntas (fatos, explicações, conceitos).\n",
      "        *   Textos criativos (poemas, roteiros, músicas, histórias).\n",
      "        *   Conteúdo informativo (artigos, resumos, relatórios).\n",
      "        *   Código de programação.\n",
      "        *   Traduções entre idiomas.\n",
      "    *   **Raciocínio e Lógica (Baseado em Padrões):** Consigo identificar padrões nos dados em que fui treinado para oferecer soluções, inferir informações e seguir instruções complexas.\n",
      "    *   **Assistência e Suporte:** Meu objetivo principal é ser um assistente útil, fornecendo informações, ajudando na criatividade, na resolução de problemas (dentro do meu escopo) e no aprendizado.\n",
      "\n",
      "4.  **Limitações:**\n",
      "    *   **Dependência de Dados:** Minha \"inteligência\" é um reflexo dos dados em que fui treinado. Se houver informações erradas, incompletas ou vieses nesses dados, eu posso reproduzi-los.\n",
      "    *   **Falta de Consciência Real:** Não \"sei\" coisas no sentido humano. Não tenho intuição, senso comum ou compreensão profunda do mundo como um ser humano. Minhas respostas são o resultado de cálculos probabilísticos sobre quais palavras ou frases são mais prováveis de seguir um determinado contexto.\n",
      "    *   **Não Gero Informação Nova no Sentido Humano:** Embora eu possa combinar informações de maneiras novas, não tenho a capacidade de ter ideias originais ou descobertas que não tenham raízes nos dados que processei.\n",
      "    *   **Atualização de Conhecimento:** Embora meu modelo seja periodicamente atualizado, não tenho acesso em tempo real a eventos muito recentes ou a informações que não foram incluídas em meu conjunto de treinamento.\n",
      "\n",
      "Em resumo, eu sou uma ferramenta tecnológica avançada, projetada para processar e gerar linguagem, atuando como um assistente digital para fornecer informações e auxiliar em diversas tarefas textuais. Não sou um ser vivo, mas uma inteligência artificial em constante evolução.\n"
     ]
    }
   ],
   "source": [
    "print(resp_test.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cfbad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAGEM_PROMPT = (\n",
    "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
    "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
    "    \"{\\n\"\n",
    "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
    "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
    "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
    "    \"}\\n\"\n",
    "    \"Regras:\\n\"\n",
    "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
    "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
    "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
    "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f80057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Dict\n",
    "\n",
    "class TriagemOut(BaseModel):\n",
    "    decisao: Literal[\"AUTO_RESOLVER\", \"PEDIR_INFO\", \"ABRIR_CHAMADO\"]\n",
    "    urgencia: Literal[\"BAIXA\", \"MEDIA\", \"ALTA\"]\n",
    "    campos_faltantes: List[str] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c097453",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_triagem = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    temperature = 0, \n",
    "    api_key = GOOGLE_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f14913d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
    "\n",
    "def triagem(mensagem: str) ->  Dict:\n",
    "    saida: TriagemOut = triagem_chain.invoke([\n",
    "        SystemMessage(content = TRIAGEM_PROMPT),\n",
    "        HumanMessage(content = mensagem)\n",
    "    ])\n",
    "    \n",
    "    return saida.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38a45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testes = [\"Posso reembolsar a internet?\",\n",
    "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
    "          \"Posso reembolsar os treinamentos da alura?\",\n",
    "          \"Quantas capivaras tem no rio pinheiros?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a69ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Posso reembolsar a internet?\n",
      " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
      "\n",
      "Pergunta: Quero mais 5 dias de trabalho remoto. Como faço?\n",
      " -> Resposta: {'decisao': 'ABRIR_CHAMADO', 'urgencia': 'MEDIA', 'campos_faltantes': []}\n",
      "\n",
      "Pergunta: Posso reembolsar os treinamentos da alura?\n",
      " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
      "\n",
      "Pergunta: Quantas capivaras tem no rio pinheiros?\n",
      " -> Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': ['contexto_politica_interna']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg_teste in testes:\n",
    "    print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
